
ssh root@dokku.me "echo export NODE_ENV="development" > /home/git/node-simple/ENV

ssh dokku@dokku.me "echo export NODE_ENV="development" > /home/dokku/node-js-simple/ENV


dokku config node-js-simple

dokku config:set node-js-simple NODE_ENV=development


node-simple app :

https://github.com/alexanderbeletsky/node-simple


———

In the main directory you have:

The vagrant files
Dokku’s files
puppet’s files

Vagrantfile inits the whole installation (virtual machine with ubuntu, git, docker, dokku, and software add with puppet)

// Take care of that (raring vs trusty)
BOX_NAME = ENV["BOX_NAME"] || "raring"
BOX_URI = ENV["BOX_URI"] || "https://cloud-images.ubuntu.com/vagrant/trusty/current/trusty-server-cloudimg-amd64-vagrant-disk1.box"


0. Cloning the dokku repo

> git clone git@github.com:progrium/dokku.git
> cd dokku

1. Local Networking : Handy for testing

› sudo nano /private/etc/hosts

and add :

10.0.0.2        dokku.me
10.0.0.2        node-simple.dokku.me

// VM of vagrant is by default assign to 10.0.0.2

2. Fire up the virtual machine : You have to be in the Vagrantfile directory

> vagrant up


3. Upload your ssh key to Dokku server, so you will be to git push code there.


> cat ~/.ssh/id_rsa.pub | vagrant ssh -- sudo sshcommand acl-add dokku computer1

> alias dokku="ssh -t dokku@<ip-of-your-instance>" // more convenient

// cat ~/.ssh/id_rsa.pub | ssh root@{{server ip address}} "sudo sshcommand acl-add dokku {{key name/descriptor}}"
// User is “dokku”, description is “computer1”
//sshcommand acl-add <user> <ssh-key-name>


// to get public key hash and compare to github by example, enter : > ssh-keygen -l -f id_rsa.pub


4. Test if everything is fine

> vagrant ssh
> docker -v


4. bis : If we have re-install dokku and changer key, don’t forget to first delete entry in client know host : “Offending key in…”

//ssh-keygen -R <nom_du serveur_SSH>
> ssh-keygen -R dokku.me


5. Deploy to Dokku

// In tuto : > git remote add local-deploy git@dokku.me:node-simple
// Go in your app directory and then “git remote add {{dokku remote name}} dokku@{{server ip address}}:{{application name}}”

//You can now see your application’s url by typing:
// “dokku url {{application name}}”

> cd node-simple
> git remote add local-deploy dokku@dokku.me:node-simple

> git push local-deploy master


example output :

-----> Deploying node-simple ...
=====> Application deployed:
       http://dokku.me:49153

To dokku@dokku.me:node-simple
 * [new branch]      master -> master


**. Install puppet

add that to the vagrant file :

    config.vm.provision :puppet do |puppet|
        puppet.manifests_path = "puppet/manifests"
        puppet.module_path = "puppet/modules"
        puppet.options = ['--verbose']
    end
**


6. Install puppet module

Methode 1 : Unpack the Tarball to continious-deployment-demo/puppet/modules and rename it to the module name which defined in manifests/init.pp (you can use “head” command on the init.pp file to verify)

Then include it into the file:

continious-deployment-demo/puppet/manifests/default.pp


They are various modules here :

https://github.com/puppetlabs/

and here :

https://github.com/example42/puppet-modules

///////////


7. Add Jenkins to puppet


Download tar file here : https://forge.puppetlabs.com/rtyler/jenkins
Add it like explained before

/!\ Don’t forget to add the dependancies /!\  : so add

https://forge.puppetlabs.com/darin/zypprepo  module.

Java module is already installed.


8. Start jenkins  (Normally automatically done)

sudo /etc/init.d/jenkins start

and

sudo /etc/init.d/jenkins stop to stop it


$$$$$$$$$$$$$$ If we want to use jenkins in another VM :


In another directory :


vagrant up a new ubuntu box with puppet for jenkins,and by example:

  config.vm.network :forwarded_port, guest: 8080, host: 2000
  config.vm.network :"private_network", ip: "10.0.0.3”,

then add dokku.me to etc/hosts (not mandatory)

$$$$$$$$$$$$$$


9. Configure vagrant port for jenkins


Guest Machine : the virtual one
Host : the real


config.vm.network "forwarded_port", guest: 80, host: 8080

The forwarded port configuration expects two parameters, the port on the guest and the port on the host


This will allow accessing port 80 on the guest via port 8080 on the host.


So we add “config.vm.network :forwarded_port, guest: 8080, host: 3000” in the Vagrantfile to access jenkins via port 3000 on the host machine.


10. Random error when vagrant provision :


If error message with provisioning :

fatal error: runtime: cannot allocate heap metadata
runtime: panic before malloc heap initialized
fatal error: runtime: cannot allocate heap metadata
make: *** [stack] Error 2

then

vagrant ssh and then in sudo :

> dd if=/dev/zero of=/swapfile bs=1024 count=1024000
> mkswap /swapfile
> swapon /swapfile

Reason : 512MB droplet is not big enough. Problem solved by adding a swapfile

OR

set vagrant virtual box memory to 1024


like explained at : http://blog.42quirks.com/install-dokku-on-amazon-ec2-ubuntu-12-04/


11. Change dokku/puppet/modules/jenkins/manifests/plugins.pp file to automatically install git jenkins plug in

List of plug in :

http://updates.jenkins-ci.org/download/plugins/


Example, add that to install git plug in:

 jenkins::plugin { "promoted-builds" : }
  jenkins::plugin { "ssh-credentials" : }
  jenkins::plugin { "credentials" : }
  jenkins::plugin { "git-client" : }
  jenkins::plugin { "multiple-scms" : }
  jenkins::plugin { "scm-api" : }
  jenkins::plugin { "token-macro" : }
  jenkins::plugin { "parameterized-trigger" : }
  jenkins::plugin { "ssh-agent" : }
  jenkins::plugin { "github-api" : }
  jenkins::plugin { "github" : }
  jenkins::plugin { "git" : }

  jenkins::plugin { "nodejs" : }

  jenkins::plugin { "ssh-slaves" : }
  jenkins::plugin { "docker-plugin" : }


https://forge.puppetlabs.com/rtyler/jenkins


/!\ Don’t forget the dependancies /!\
http://csfreebird.blogspot.be/2012/08/installing-jenkins-plugin-manually.html


/!\ Attention ASCII /!\
" is not the same then “


12. Launch a new job in jenkins

go to “new job”, set a name, select git
Provide the path of GitHub repository under “GitHub Project” : http://…., sans .git
provide “repository URL” for “GIT” under “Source Code Management”. : git://github… .git

select option for “What trigger the build” : “Build when a change is pushed to GitHub”
set before build?  Nothing for now
action after build? Nothing for now

Now, we have configured Jenkins job in such a way that whenever a change is committed to GitHub repository - this will trigger build process on Jenkins.


repository url : 
// no parameters => .git ?


12 bis

///////// Configure git credentials; in the guest machine run :

> ssh-keygen -t rsa -C "label"

we don’t need passphrase (Do we?)

Passphrase : used to crypt private key for better security
No way to someone else to access VM


It generates a private/public key pair

Then put your public key on github; and put your private key on Jenkins

Then 

> ssh -T git@github.com

/////////// to add key fingerprint to known host

Just take the same key pair then before ! So just add existing host private key to jenkins



13

Jenkins is for the moment run locally, so github can’t trigger jenkins

Instead we’ll ask jenkins to pull frequently github —> Cron like


So, choose “build periodically option”

Planning :

*/2 * * * *



14


Fichier Hello.java sur git


script shell jenkins :

javac Hello.java;
java Hello


15. Post build options


I believe you can just add two git repositories under the "source code management" section, and then specify that you want to build REPOLOCALNAME/branch, and then at the end under 'Git publisher' specify you want to merge and push to the remote branch. (ie. BranchToPush=branchname and TargetRemoteName= REMOTEREPONAME)

*Remember, the names are specified under advanced options of the repository when you add it under the SCM section.

—

So, add a second repository url : 

dokku@dokku.me:node-simple

with the same credentials then the first repo

Then, set a name, by example : remoterepo
 and under “Branches to build”, puts “origin/master”

set a name too for the first repo, “origin”


Then, choose post build option “git publisher”

branch to push : master



For the example the first repo is a fork of node-simple


——

http://programmaticponderings.wordpress.com/2013/11/13/building-a-deployment-pipeline-using-git-maven-jenkins-and-glassfish-part-2-of-2/


BUT Don’t choose the Merge option!!!!


just a post-it :

Use the git remote rm command to remove a remote URL from your repository.

> git remote -v
> git remote rm destination


—


Very CI&CD interesting articles :

http://jenkins-le-guide-complet.batmat.cloudbees.net/html/book.html

http://jenkins-le-guide-complet.batmat.cloudbees.net/html/chapter-security.html

http://www.methodsandtools.com/archive/archive.php?id=121

http://catalyst-zero.com/release-your-app/

http://www.kaczanowscy.pl/tomek/2012-07/jenkins-plugins-part-iii-towards-continuous-delivery

http://www.agitech.co.uk/implementing-a-deployment-pipeline-with-jenkins/

http://www.agitech.co.uk/deployment-pipelines-with-jenkins-puppet-and-jbehave/

http://www.infoq.com/articles/orch-pipelines-jenkins

http://thediscoblog.com/blog/2014/01/24/continuous-delivery-for-heroku-with-jenkins/

http://www.carbonsilk.com/node/deploying-nodejs-apps/


———


Docker commands:

Commands List


sudo docker [option] [command] [arguments]


sudo docker images : List images

sudo docker kill : kill a running container

sudo docker ps : List containers

sudo docker restart : Restart a running container

sudo docker rm : Remove one or more containers

sudo docker rim : Remove one or more images

sudo docker start : Start a stopped container

…

Build process:

# Build an image using the Dockerfile at current location
# Tag the final image with [name] (e.g. *nginx*)
# Example: sudo docker build -t [name] .
sudo docker build -t memcached_img .



…

———

A dedicated Jenkins job builds an image from this Dockerfile. We keep the image building as a separate task because it's time consuming… once an image is built, containers can be run from it over and over and the start up time is practically nil!


——

Jenkins+Docker COnfiguration


Goto Jenkins Configuration page by clicking on Manage menu or browsing to the URL http://localhost:8080/configure
Scroll down to Cloud Section
Click on the `Add a new cloud` pop-up menu button which should have an option - docker


—


Docker image:

- Basic docker jenkins slave (image) :

https://registry.hub.docker.com/u/evarga/jenkins-slave/dockerfile



- Public docker images:

https://github.com/docker/docker/wiki/Public-docker-images



//
- Sidenote :


REPOSITORY             TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
dokku/node-simple      latest              6018a554b6c8        20 hours ago        889.8 MB
progrium/buildstep     latest              dc1e9e425683        41 hours ago        866.4 MB
evarga/jenkins-slave   latest              f3ac335af281        3 months ago        438 MB


Our dokku app is on the repository name “dokku/node-simple”
//


> sudo docker pull evarga/jenkins-slave

> sudo docker images

> sudo docker ps -a


Ensuite, pour lancer une commande avec, il faut faire docker run id_image commande. Ceci va lancer l’image, lancer la commande, et dès que la commande se termine, arrêter l’image :


sudo docker run -P -d evarga/jenkins-slave


Thanks to the -P option used in the run command, all the exposed ports are mapped automatically. So if you go to yourDockerHost:49154 with a web browser, you’ll have the running Nuxeo instance.


or


> sudo docker run -d -p 0.0.0.0:2222:22 -t -i evarga/jenkins-slave

-d means in background

> ssh jenkins@localhost -p 2222


Works.

If your host needs to allow connections from a jenkins instance hosted on a different machine, you will need to open up the TCP port. This can be achieved by editing /etc/init/docker.conf, and setting (for example) 



> vagrant ssh

> sudo nano /etc/default/docker
ajouter :

DOCKER_OPTS="-H 127.0.0.1:4243 -H unix:///var/run/docker.sock"

ou plutôt

DOCKER_OPTS="-H 0.0.0.0:4243 -H unix:///var/run/docker.sock"

then


sudo service docker restart



Then go to jenkins, and make a test connection to http://localhost:4243


—

> sudo docker inspect 013d47357d20 | grep IP

> sudo ssh jenkins@172.17.0.42

Works

--

> sudo docker rm -f $(sudo docker ps -a | grep evarga)


—

Show only image ID's

> sudo docker images -q

—————


Credentials for slave server:


> ssh-keygen -t rsa


> chmod 755 ~/.ssh


> echo 'ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCr5lzMXzgxtWqYVWYzaxwoCzO9DPNqkPgJN/1Zire/FcisSIJkGU8E7E8Cpl5U3Fj+2whD9LkEhHOc6nwuRC8C4uDUxE9b54fwL0BqhEy6ADv3vOVPOu1SUg0g10A/+bmcJ+l5ER1LcOMzUP88chXZVRoFV9VjAbHlI8fxWaw34J66oJd7xRpYGlnuyfyCrrl5Wb+tssycZEAezs7r3NRuEvjcoGEgLiKBHqxWCekyq4VQw9pX0303eBKCMsy56z6OegtEtpF4LEubUBGSVPfzN6aVLhxP6z+P3NbYonxBRGiDxnI86jiViii/dljCp0sWE8yQtHUNu/D2zsOCD88L label' > /home/jenkins/.ssh/authorized_keys


>  chmod 644 ~/.ssh/authorized_keys


> exit


> sudo docker commit f098b5830556 jenkins-test-cred



http://www.centos.org/docs/5/html/5.2/Deployment_Guide/s3-openssh-rsa-keys-v2.html

http://varmenise.tumblr.com/post/87976165063/docker-on-centos-jenkins



——


You can see that it creates a user jenkins:jenkins.

So you would naturally use these credentials to access it by jenkins: this is wrong—> you need ssh authentication to make it work with the docker-plugin.

pull the container: 

> docker pull evarga/jenkins-slave

Once you have done this you will see it appearing in the list of images (sudo docker images)


run the container: 

> docker run -i -t evarga/jenkins-slave /bin/bash

create the ssh key pair

> ssh-keygen -t rsa


> echo 'AuthorizedKeysFile /etc/ssh/authorized_keys' >> /etc/ssh/sshd_config


> echo 'ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCr5lzMXzgxtWqYVWYzaxwoCzO9DPNqkPgJN/1Zire/FcisSIJkGU8E7E8Cpl5U3Fj+2whD9LkEhHOc6nwuRC8C4uDUxE9b54fwL0BqhEy6ADv3vOVPOu1SUg0g10A/+bmcJ+l5ER1LcOMzUP88chXZVRoFV9VjAbHlI8fxWaw34J66oJd7xRpYGlnuyfyCrrl5Wb+tssycZEAezs7r3NRuEvjcoGEgLiKBHqxWCekyq4VQw9pX0303eBKCMsy56z6OegtEtpF4LEubUBGSVPfzN6aVLhxP6z+P3NbYonxBRGiDxnI86jiViii/dljCp0sWE8yQtHUNu/D2zsOCD88L label' > /etc/ssh/authorized_keys



> echo "    IdentityFile /root/.ssh/id_rsa" >> /etc/ssh/ssh_config



————


For the test, to disable the fingerprint authentification :


Add the following lines to the beginning of /etc/ssh/ssh_config


Host *
   StrictHostKeyChecking no
   UserKnownHostsFile=/dev/null


Options:

The Host subnet can be * to allow unrestricted access to all IPs.
Edit /etc/ssh/ssh_config for global configuration or ~/.ssh/config for user-specific configuration.


————

man hier

——-

# We're being careful here in that we're only cleaning up containers which are no longer running

sudo docker ps -a | grep "Exit" | awk '{print $1}' | while read -r id ; do
  sudo docker rm $id
done





——————

add_pub_etc_et_jenkins :

Je n’ai pas realise les commandes :

> ssh-keygen -t rsa

> echo "    IdentityFile /root/.ssh/id_rsa" >> /etc/ssh/ssh_config


De plus, j’ai ajoute au server (docker) la cld publique du root et de l’user jenkins



Add the following lines to the beginning of /etc/ssh/ssh_config, server side (docker)


echo "    StrictHostKeyChecking no
    UserKnownHostsFile=/dev/null" >> /etc/ssh/ssh_config


———-


pub_jenkins_all_com :


toutes les commandes et cle publique jenkins et cld prive de la cle publique jenkins.

Ensuite test avec autre cld privée




—————




sudo -u jenkins ssh-keygen

That will generate the key for you here:
/var/lib/jenkins/.ssh/id_rsa.pub


ok, then



echo 'ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCr5lzMXzgxtWqYVWYzaxwoCzO9DPNqkPgJN/1Zire/FcisSIJkGU8E7E8Cpl5U3Fj+2whD9LkEhHOc6nwuRC8C4uDUxE9b54fwL0BqhEy6ADv3vOVPOu1SUg0g10A/+bmcJ+l5ER1LcOMzUP88chXZVRoFV9VjAbHlI8fxWaw34J66oJd7xRpYGlnuyfyCrrl5Wb+tssycZEAezs7r3NRuEvjcoGEgLiKBHqxWCekyq4VQw9pX0303eBKCMsy56z6OegtEtpF4LEubUBGSVPfzN6aVLhxP6z+P3NbYonxBRGiDxnI86jiViii/dljCp0sWE8yQtHUNu/D2zsOCD88L label' > /etc/ssh/authorized_keys

test_var_lib_key






docker ps -a | grep 'weeks ago' | awk '{print $1}' | xargs docker rm



sudo groupadd docker
sudo gpasswd -a ${USER} docker
sudo service docker.io restart
+ exit & log in


———

> vagrant up

> vagrant ssh
> mkdir dev
> cd dev
> cp /vagrant/test_slave/* .
> sudo docker build -t bill .


> sudo nano /etc/default/docker

DOCKER_OPTS="-H 127.0.0.1:4243 -H unix:///var/run/docker.sock"

> sudo gpasswd -a vagrant docker
> sudo service docker restart



> sudo -u jenkins ssh-keygen
> sudo chmod 755 .ssh
> cd .ssh
> sudo chmod 644 *

> docker run -i -t bill  /bin/bash
> cd /var/lib/jenkins
> echo …. >> authorized_keys
> docker commit 973685f7e17d kill


———


Graylog : Vagrant Box

https://github.com/hggh/graylog2-vagrant


> git clone --recursive https://github.com/hggh/graylog2-vagrant.git
> cd graylog2-vagrant
> vagrant up
> vagrant reload --provision  # because puppet needs to run twice to create GELF inputs
> vagrant ssh

http://localhost:9000/

Username: admin
Password: yourpassword

cronjob runs every minute to push sample data into Graylog2


Add 

config.vm.network :"private_network", ip: "10.0.0.4"

to vagrant file

—

Then, in the source machine

…First add rsyslog module to puppet… then


> sudo nano /etc/rsyslog.conf
 
Add this line :

*.* @<ip-server-graylog2>:514

then 

> /etc/init.d/rsyslog restart
> sudo service rsyslog status (to verify)




